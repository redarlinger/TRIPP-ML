# -*- coding: utf-8 -*-
"""tools.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NJ7zOWDo0wP4pwjZgHbcYuE8vXeWz-KO
"""
#written in collaboration: Ben Fogiel and Rachel Darlinger
#this is just the directory of all of the helpful functions. To run, must be but into separate .py file

import cv2

#from google.colab import drive
#not needed unless using collab

# Commented out IPython magic to ensure Python compatibility.
#drive.mount('/content/drive')
# %cd /content/drive/My\ Drive


"""**Changing the labels**"""

import glob

## assuming working dir is 'stars_data/' ##

dirs = glob.glob('val/*')

for d in dirs:
	f = open(f"{d}/1.txt","r")
	line = f.read()
	f.close()

	l = line.split()

	f = open(f"{d}/1.txt","w")
	f.write(f'{l[0]} {l[1]} {l[2]} {float(l[3])/400} {float(l[4])/400}')
	f.close()

"""**Creating the label directory list**"""

import random
import glob

## assuming working dir is 'stars_data/' ##
#assert os.getcwd() == '/content/drive/My Drive/Darknet Training Sets/darknet/stars_data/', f"you're in the wrong dir (current dir: {os.getcwd()})"

paths = []
abs_dir = '/mnt/annex/YOLO_data/Multi_trans/residual_pngs/'

pairs = glob.glob(f'{abs_dir}/*')
for p in pairs:
    paths.append(f'{abs_dir}{p}/1.png')

# scamble paths so we can randomly assign training and val sets
random.shuffle(paths)

# 70% training 15% val 15% test
cut_train = int(len(paths)*0.7)
cut_val= int(len(paths)*0.85)

train = paths[:cut_train] #takes the first 70%
val = paths[cut_train:cut_val] #takes the next 15%
test = paths[cut_val:] #takes the last 15%

# check len of each set
assert len(val)+len(train)+len(test)==len(paths), 'val and training sets are of incorrrect lengths'

# write txts
textfile = open("sets/trainMultiTrans.txt", "w")
for element in train:
    textfile.write(element + "\n")
textfile.close()

textfile = open("sets/valMultiTrans.txt", "w")
for element in val:
    textfile.write(element + "\n")
textfile.close()

textfile = open("sets/testMultiTrans.txt", "w")
for element in test:
    textfile.write(element + "\n")
textfile.close()

import glob
from os.path import exists

## assuming working dir is 'stars_data/' ##

types = glob.glob('1sec/*')
paths = []
abs_dir = '/content/drive/My Drive/Darknet Training Sets/darknet/stars_data/'

for t in types:
  pairs = glob.glob(f'{t}/*')
  for p in pairs:
    if not exists(f'{p}/1.png') or not exists(f'{p}/0.png'):
      print(p)

"""**Replacing Table txts**"""

ls

import glob
import os
import shutil

assert os.getcwd() == '/content/drive/MyDrive', f"you're in the wrong dir (current dir: {os.getcwd()})"

parent_dest = "Darknet Training Sets/darknet/stars_data"
parent_origin = "SETI/data"
mag_pairs = glob.glob(f"{parent_origin}/1sec/*")

for m in mag_pairs:
  pairs = glob.glob(f"{m}/*")
  for p in pairs:
    origin = f"{p}/1.txt"
    shutil.copyfile(origin, origin.replace(parent_origin, parent_dest))

"""**Flip Image**"""

import cv2
import glob

assert os.getcwd() == '/content/drive/MyDrive', f"you're in the wrong dir (current dir: {os.getcwd()})"

mag_pairs = glob.glob("Darknet Training Sets/darknet/stars_data/1sec/*")
for m in mag_pairs:
  pairs = glob.glob(f"{m}/*")
  for p in pairs:
    img = cv2.imread(f"{p}/1.png")
    flip_img = cv2.flip(img, 0)
    cv2.imwrite(f"{p}/1.png", flip_img)

"""**Gauging Accuracy**"""

import cv2
import glob
import pandas as pd

with open('cfg/coco.names', 'r') as f:
    classes = f.read().splitlines()

net = cv2.dnn.readNetFromDarknet('cfg/yolov4_stars.cfg', 'backup/yolov4_stars_last.weights')

model = cv2.dnn_DetectionModel(net)
model.setInputParams(scale=1 / 255, size=(416, 416), swapRB=True)

acc = []
pairs = glob.glob('stars_data/1sec/13_14/*')
iter = 0
for p in pairs:
  iter += 1
  if iter == 10:
    break
  img_path = f'{p}/1.png'
  img = cv2.imread(img_path)
  classIds, scores, boxes = model.detect(img, confThreshold=0.1, nmsThreshold=0.1)

  f = open(f"{p}/1.txt","r")
  line = f.read().split()
  f.close()
  ground_truth = 400*float(line[1]), 400*float(line[2])

  if not len(scores):
    acc.append([img_path[16:],0,True,ground_truth[0], ground_truth[1],0,0])

  for score,box in zip(scores,boxes):
    center = box[0]+box[2]/2, box[1]+box[3]/2 # box = x-topLeft, y-topLeft, width, height

    false_positive = abs(ground_truth[0] - center[0]) > 20 or abs(ground_truth[1] - center[1]) > 20
    acc.append([
        img_path[16:],
        score, # confidence
        false_positive, # if deviates more than 20 pixels
        ground_truth[0], # true x-center
        ground_truth[1], # true y-center
        center[0], # predicted x-center
        center[1], # predicted y-center
    ])

pd.DataFrame(acc,columns=['img','confidence','false pos','true x','true y','pred x','pred y']).to_csv('test.csv')

"""**Real Set Txts**"""

cd SDI Project/darknet/real_set/

import random
import glob

img = glob.glob('imgs/*')
paths = []
abs_dir = '/content/drive/My Drive/SDI Project/darknet/real_set/'

for t in img:
  pairs = glob.glob(f'{t}')
  for p in pairs:
    paths.append(f'{abs_dir}{p}')

# write txts
textfile = open("real_set1.txt", "w")
for element in paths:
    textfile.write(element + "\n")
textfile.close()
